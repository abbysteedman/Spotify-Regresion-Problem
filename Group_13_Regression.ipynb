{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBP_DOVgvCOb"
      },
      "source": [
        "# **Spotify Regression Problem**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group 13:**\n",
        "Abby Steedman: 202353510,\n",
        "Benjamin Ashworth: 202385669,\n",
        "Christopher Reilly: 202365778\n",
        "Haseeb Ramey: 202378564,\n",
        "Kieran McAvoy: 202394078\n"
      ],
      "metadata": {
        "id": "IxbmY3i-iL0j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GojT0X5-m-WK"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVsVSntUx_C1"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "Spotify, one of the most popular music streaming services, provides listeners with songs, albums and podcasts from the latest hits to classics. But what makes a song popular?  We aim to build a model that can predict the popularity of a song based on the its musical features such as temperament and loudness. As popularity is a numerical value, we will be treating this as a regression problem. Used as the preferred evaluation metric for regression problems, models performance will be measured by the Root Mean Square Error (RMSE) which will give us an understanding of how much error the model makes when predicting values.\n",
        "\n",
        "**Required Libraries**\n",
        "\n",
        "This notebook uses several python packages which were essential to performing this analysis. These were NumPy, Pandas, Sci-Kit Learn,  MatplotLib and Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLgtl1Xj7P1B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcWkQAY80gRx"
      },
      "outputs": [],
      "source": [
        "# load training & test datasets\n",
        "train = pd.read_csv(\"CS98XRegressionTrain.csv\")\n",
        "test = pd.read_csv(\"CS98XRegressionTest.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploring, Cleaning and Preparing the Data\n",
        "\n",
        "We begin by exploring and visualising the data to understand what preparation and preprocessing needs to take place to ensure our data is clean and capable of being fed into our models."
      ],
      "metadata": {
        "id": "9RIBlYZ1FU6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCnU91QQeNnT"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR0SZeUPeiGA"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 12))\n",
        "alpha_level = 0.65\n",
        "\n",
        "axes[0].scatter(train.index, train['pop'], alpha=alpha_level)\n",
        "axes[0].set_title('Figure 1: Scatterplot of Songs Popularity')\n",
        "axes[0].set_xlabel('Songs')\n",
        "axes[0].set_ylabel('Popularity')\n",
        "\n",
        "train['top genre'].value_counts().plot(kind='bar', ax=axes[1])\n",
        "axes[1].set_title('Figure 2: Bar Chart of Genres')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L5V1UOnprtni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdND4nHnejrz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "train.hist(bins=50, figsize=(12,7))\n",
        "plt.suptitle('Figure 3: Histograms of Training Set Variables')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graphs a few things are noticeable:\n",
        "1. Figure 1 shows that the data is messy and not linear, a straight line would never fit this complex data properly, therefore we need to consider how we can combat this to create an effective model.\n",
        "2. Figure 2 shows the extent of the messiness of the data, and is not very helpful in showcasing the distribution of the top genre attribute in the training set. Clearly there is a significant number of different genres, some with very little instances in each category. This could make the data very difficult for the algorithm to learn from and tricky to generalise. On inspection of the rest of the data, it is assumed that the same issue is present in the 'artist', 'title' and 'year' features.\n",
        "3. Finally, in figure 3 we can see that many attributes are tail-heavy having most instances on the left handside. This could make it difficult for the algorithm to detect patterns which would produce accurate predictions. Further, the attributes have very different scales. For example, 'dB' ranges from -25 to 0 compared with duration, which ranges from 100 to 500. This could cause potential issues. Therefore, we will need to consider scaling to ensure all attributes are are aligned to the same scale to allow the model to learn effectively.\n",
        "\n",
        "Thus, it is evident that a significant volume of data cleaning and preperation is needed before we can fit to and predict from our models."
      ],
      "metadata": {
        "id": "2JAwek6r3wve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "68rjDqhP90HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dQfCB_fgX_F"
      },
      "outputs": [],
      "source": [
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxSosn0FMLtI"
      },
      "source": [
        "Initial analysis showed that there was a small number of null values in the 'top genre' feature in the training set, we pondered a few options on how to approach this. Firstly, subsituting the nulls with the mode. We decided this was not an optimal solution as genres differ a lot dependent on the song, the genre with the most number of songs may not necessarily be the genre of the song that is null. Further, as we did not want to create an inaccurate model, dropping these rows to avoid any misclassification seemed like the most ideal solution. As these missing genres were less than 5% of all training instances, we decided to drop these columns to avoid our model being trained with inaccurate and incorrect data.\n",
        "\n",
        "On the other hand in the test set, only one value was null (again in the 'Top Genre') category. In this case, we filled the null value with the mode of 'Top Genres', which was 'adult standards'. As it was only one value, we judged that filling it with the mode would not have made as much difference as filling the NAs in the training data, of which there were 15.\n",
        "\n",
        "---\n",
        "\n",
        "**Splitting the Data**\n",
        "\n",
        "Instead of performing a test-train split, as the dataset was already split into test and train datasets, we decided to test on our target ('pop' from the training dataset ). Although this could lead to overfitting in somecases, as our training data was so small, we wanted to include as many instances as possible in the training data to try ensure our model was as accurate to the highest extent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNkp66vlgls_"
      },
      "outputs": [],
      "source": [
        "#split the data, drop NAs in the train and fill the NA in the test\n",
        "train = train.dropna()\n",
        "train_target = train['pop']\n",
        "train_data = train.drop(['pop'], axis=1)\n",
        "test = test.fillna('adult standards')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "id": "G1AJvot_Lf0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ddkbkc-682"
      },
      "source": [
        "**Irrelevant Features**\n",
        "\n",
        "When developing our algorithim, we decided to drop some relatively irrelavant and arbitrary columns that are not related to a songs popularity. These included *'Id', 'artist'* and '*title*'. *'Id'* was simply to define it within the dataset, thus would render useless in predicting the popularity of a song. Moreover, we decided to drop '*title*' as every song title is different, so having to one-hot encode for example would have added over 300 attributes into the dataset. This would have meant the model was slow and thus ineffcient, and would heavily overfit to the training data, as the titles in the test set would be entirely different so the model would not generalise well. We further chose to drop *'artist'* as it also contained many unique values, which would create difficulty when changing them to numerical values, slowing down the model and causing overfitting to the training data.\n",
        "\n",
        "This would allow our models to learn easily from the training data and make better predictions. We also explored the structure of the 'top genre' category to see if we wanted to keep it in, as genre is generally a distinct indicator of a songs popularity (E.g. If a genre is popular, artists are likely to release songs into that genre to have a popular song). Thus, we decided to keep top genre within our data, however perform some transformations to allow it to be more accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlJGxZv76-00"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.drop(['title', 'Id', 'artist'], axis=1)\n",
        "test = test.drop(['title', 'Id', 'artist'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-AMaSO0Cpzb"
      },
      "outputs": [],
      "source": [
        "train_data['top genre'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvw_xkDNC0Un"
      },
      "outputs": [],
      "source": [
        "test['top genre'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNoKdmmC7nym"
      },
      "source": [
        "**Feature Engineering**\n",
        "\n",
        "To first reduce the number of features in the training set to regularise the model, improve its accurracy and ability to generalise to unseen data, we took a second look at our variables. Looking at correlations between the numerical variables can help with understanding their relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV-rwDvx8jgF"
      },
      "outputs": [],
      "source": [
        "#transform to numerical to make correlations work\n",
        "train_numerical = train_data.drop(['year', 'top genre'], axis=1)\n",
        "test_numerical = test.drop(['year', 'top genre'], axis=1)\n",
        "corr = train_numerical.corr()\n",
        "sns.heatmap(corr)\n",
        "plt.title('Figure 4: Heatmap of Correlations between Numerical Variables ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBX5tD-W-jsh"
      },
      "source": [
        "Figure 4, shows that 'nrgy' (Energy) and 'dB' (Decibels) are the most strongly correlated variables (*p = 0.08*). To avoid any multicollinearity issues that could potentially interfere with the models interpretation of the effect of the variables on the target, we decided to combine energy and decibels into one feature. Furthermore, combining highly correlated variables also enables the model to find patterns in the data that may have gone unnoticed without the combining of attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb7PlvyuYKha"
      },
      "outputs": [],
      "source": [
        "train_numerical['LoudEnergy'] = train_numerical['nrgy'] * train_numerical['dB']\n",
        "test_numerical['LoudEnergy'] = test_numerical['nrgy'] * test_numerical['dB']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCN0qH1WYQhC"
      },
      "outputs": [],
      "source": [
        "train_num_attribs = list(train_numerical)\n",
        "train_num_attribs\n",
        "test_num_attribs = list(test_numerical)\n",
        "test_num_attribs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCeHXmsw7r73"
      },
      "source": [
        "**Years - Grouping and One Hot Encoding**\n",
        "\n",
        "We decided to one-hot encode year. Given the number of years represented in the dataset this would have resulted in many additional features. To reduce this, we first reduced years down to their respective decade and then one-hot encoded this transformed feature.\n",
        "We then created a function that rounds every year down to the starting year of its decade. This grouped years into decades to reduce the number of features in the year attribute. After one hot encoding the manipulated decades feature, we dropped the '1940s' decade from both the test and train sets to avoid the dummy variable trap.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBkBgvkzBnBp"
      },
      "outputs": [],
      "source": [
        "train_years = train_data[['year']]\n",
        "test_years = test[['year']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pweyWCM-V74O"
      },
      "outputs": [],
      "source": [
        "###turning year into decades and one-hot encoding decades\n",
        "def convert_to_decade(year):\n",
        "    return (year // 10) * 10\n",
        "\n",
        "train_decades = train_years[['year']]\n",
        "train_decades['decade'] = train_decades['year'].apply(convert_to_decade)\n",
        "train_decades = train_decades.drop(['year'], axis=1)\n",
        "train_decades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-orfRSTvWGW"
      },
      "outputs": [],
      "source": [
        "###doing the same for test...\n",
        "test_decades = test_years[['year']]\n",
        "test_decades['decade'] = test_decades['year'].apply(convert_to_decade)\n",
        "test_decades = test_decades.drop(['year'], axis=1)\n",
        "test_decades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1THIrI0ZTGG"
      },
      "outputs": [],
      "source": [
        "###ordinal encoding train data\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "train_decades_encoded = ordinal_encoder.fit_transform(train_decades)\n",
        "train_decades_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWX3UtIwy-JH"
      },
      "outputs": [],
      "source": [
        "train_decade_cat = ordinal_encoder.categories_\n",
        "train_decade_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKllGOl9v7Lk"
      },
      "outputs": [],
      "source": [
        "###for test...\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "test_decades_encoded = ordinal_encoder.fit_transform(test_decades)\n",
        "test_decades_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6W7rMvHzByt"
      },
      "outputs": [],
      "source": [
        "test_decade_cat = ordinal_encoder.categories_\n",
        "test_decade_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW2JdnaI_k7O"
      },
      "outputs": [],
      "source": [
        "###one-hot encoding training decades\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "train_decades_1hot = cat_encoder.fit_transform(train_decades)\n",
        "train_decade_categories = train_decades\n",
        "train_decades_1hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkJUdgGBwod7"
      },
      "outputs": [],
      "source": [
        "###one-hot encoding testing decades\n",
        "test_decades_1hot = cat_encoder.fit_transform(test_decades)\n",
        "test_decade_categories = test_decades\n",
        "test_decades_1hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNy90G7p_m46"
      },
      "outputs": [],
      "source": [
        "###assigning correct columns to training encoded data\n",
        "train_decade_enc = pd.DataFrame(train_decades_1hot)\n",
        "train_decade_enc.columns = train_decade_cat[0]\n",
        "train_decade_enc.index = train_data.index\n",
        "train_decade_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QdV2XE_xlVI"
      },
      "outputs": [],
      "source": [
        "###assigning correct columns to testing encoded data\n",
        "test_decade_enc = pd.DataFrame(test_decades_1hot)\n",
        "test_decade_enc.columns = test_decade_cat[0]\n",
        "test_decade_enc.index = test.index\n",
        "test_decade_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rWCkVWB_qZb"
      },
      "outputs": [],
      "source": [
        "### DROPPING 1940 FROM the encoded datasets, to avoid the dummy trap\n",
        "train_decade_enc.columns = train_decade_enc.columns.astype(str)\n",
        "test_decade_enc.columns = test_decade_enc.columns.astype(str)\n",
        "train_decade_enc = train_decade_enc.drop(['1940'],axis=1)\n",
        "test_decade_enc = test_decade_enc.drop(['1940'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALIyDgPk_upL"
      },
      "outputs": [],
      "source": [
        "train_decade_enc.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4rO0fyV_zAm"
      },
      "outputs": [],
      "source": [
        "test_decade_enc.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkCuuoci_D9h"
      },
      "source": [
        "**Genre - One Hot Encoding**\n",
        "\n",
        "Additionally, rather than dropping the nominal category of *‘top genre’*, which we wanted to keep within the model’s data, we recoded it to be represented numerically. One function we could have used was Sci-Kit Learn’s Ordinal Encoder, which converts nominal values to numerical ones. However, given that the categories we want to convert are nominal, recoding them to numerical values within the same feature would potentially cause our model to detect relationships between instances that do not exist.\n",
        "\n",
        "Instead, we used Sci-Kit Learn's OneHotEncoding function. This creates a single binary feature per nominal category in the original feature (e.g. An attribute equal to 1 when the genre is *‘adult standards’* and 0 when another genre). The code for our one-hot encoding of *‘top genre’* in both the test and train is shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzYeZi04B4Ve"
      },
      "outputs": [],
      "source": [
        "train_genre = train_data[['top genre']]\n",
        "test_genre = test[['top genre']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlWiMAVq_XkC"
      },
      "outputs": [],
      "source": [
        "###ordinal encoding genre for the train\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "train_genre_encoded = ordinal_encoder.fit_transform(train_genre)\n",
        "train_genre_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeCEdG5M3rWC"
      },
      "outputs": [],
      "source": [
        "train_genre_cat = ordinal_encoder.categories_\n",
        "train_genre_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYkQwIM53dZy"
      },
      "outputs": [],
      "source": [
        "###and for the test\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "test_genre_encoded = ordinal_encoder.fit_transform(test_genre)\n",
        "test_genre_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PITfaw-8_6s_"
      },
      "outputs": [],
      "source": [
        "test_genre_cat = ordinal_encoder.categories_\n",
        "test_genre_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMDmpTtL_6mh"
      },
      "outputs": [],
      "source": [
        "###one hot encoding for the train\n",
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "train_genre_1hot = cat_encoder.fit_transform(train_genre)\n",
        "train_genre_categories = train_genre\n",
        "train_genre_1hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0J0fUng4ELa"
      },
      "outputs": [],
      "source": [
        "###and for the test\n",
        "test_genre_1hot = cat_encoder.fit_transform(test_genre)\n",
        "test_genre_categories = test_genre\n",
        "test_genre_1hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVq2xc4i_6g4"
      },
      "outputs": [],
      "source": [
        "###matching columns for the train\n",
        "train_genre_enc = pd.DataFrame(train_genre_1hot)\n",
        "train_genre_enc.columns = train_genre_cat[0]\n",
        "train_genre_enc.index = train_data.index\n",
        "train_genre_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_wOg7yS4Qrn"
      },
      "outputs": [],
      "source": [
        "###matching columns for the test\n",
        "test_genre_enc = pd.DataFrame(test_genre_1hot)\n",
        "test_genre_enc.columns = test_genre_cat[0]\n",
        "test_genre_enc.index = test.index\n",
        "test_genre_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTFn4uaL__It"
      },
      "source": [
        "However, one-hot encoding *‘top genre’* resulted in an extremely large number of input features. The feature had over 300 unique values in the training data, which would have potentially slowed down our model if it remained in one-hot encoded form. To combat this, we manipulated the one-hot encoded genre data into fewer categories to speed up training whilst still having genres as features our model could learn from.\n",
        "To reduce the feature numbers, we retained the top 3 most numerous genres from the test and training sets (which happpened to be the same three genres) and collapsed the remaining genre columns into one single column named ‘Other Genres’. This reduced the number of genre columns down to 4. Finally, we dropped the feature 'dance pop' from both the train and test datasets.\n",
        "\n",
        "The code for collapsing the genre data and reducing the features is shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-JN-6stALDS"
      },
      "outputs": [],
      "source": [
        "train_top_genres = train_genre_enc[['adult standards', 'album rock', 'dance pop']]\n",
        "train_top_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpFRIsiHALSB"
      },
      "outputs": [],
      "source": [
        "train_collapsed_data = train_genre_enc.drop(['adult standards', 'album rock', 'dance pop'], axis=1)\n",
        "train_collapsed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-AYmEr8ASlo"
      },
      "outputs": [],
      "source": [
        "start_column = 'acoustic blues'\n",
        "end_column = 'yodeling'\n",
        "start_index = train_collapsed_data.columns.get_loc(start_column)\n",
        "end_index = train_collapsed_data.columns.get_loc(end_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsCkjDRLASdD"
      },
      "outputs": [],
      "source": [
        "train_collapsed_genre = train_collapsed_data.loc[:, start_column:end_column].sum(axis=1)\n",
        "train_collapsed_data['Other Genres'] = train_collapsed_genre\n",
        "train_collapsed_data\n",
        "train_collapsed_genres = train_collapsed_data[['Other Genres']]\n",
        "train_collapsed_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDbZJ_ceASTR"
      },
      "outputs": [],
      "source": [
        "train_genre_collapsed = train_top_genres.join(train_collapsed_genres)\n",
        "train_genre_collapsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ialbt1ht5uNM"
      },
      "outputs": [],
      "source": [
        "###doing the same for the test data\n",
        "test_top_genres = test_genre_enc[['adult standards', 'album rock', 'dance pop']]\n",
        "test_top_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYhWv9hJ6cls"
      },
      "outputs": [],
      "source": [
        "test_collapsed_data = test_genre_enc.drop(['adult standards', 'album rock', 'dance pop'], axis=1)\n",
        "test_collapsed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt5LvwxZ6he2"
      },
      "outputs": [],
      "source": [
        "start_column = 'alternative country'\n",
        "end_column = 'neo mellow'\n",
        "start_index = test_collapsed_data.columns.get_loc(start_column)\n",
        "end_index = test_collapsed_data.columns.get_loc(end_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hl8gjls6tIP"
      },
      "outputs": [],
      "source": [
        "test_collapsed_genre = test_collapsed_data.loc[:, start_column:end_column].sum(axis=1)\n",
        "test_collapsed_data['Other Genres'] = test_collapsed_genre\n",
        "test_collapsed_data\n",
        "test_collapsed_genres = test_collapsed_data[['Other Genres']]\n",
        "test_collapsed_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaRAKp_P7U3v"
      },
      "outputs": [],
      "source": [
        "test_genre_collapsed = test_top_genres.join(test_collapsed_genres)\n",
        "test_genre_collapsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI3dCGdq52BD"
      },
      "outputs": [],
      "source": [
        "###dropping 'dance pop' from the encoded, collapsed datasets in order to avoid the dummy variable trap\n",
        "train_genre_collapsed = train_genre_collapsed.drop(['dance pop'], axis=1)\n",
        "train_genre_collapsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SyHJjHK7_Cx"
      },
      "outputs": [],
      "source": [
        "test_genre_collapsed = test_genre_collapsed.drop(['dance pop'], axis=1)\n",
        "test_genre_collapsed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6vnDpMeXr8o"
      },
      "source": [
        "# Feature Scaling\n",
        "\n",
        "As seen in the Figure 3 (above), for the numerical attributes of the training data, much of the data is placed along different scales. For example, in decibels (‘dB’) values can run from -25 to 0, whilst in beats per minute (BPM) values can run from 0 to 200. Scales of varying length can prove problematic for certain ML algorithms like Support Vector Machines (SVM) we decided to scale the numerical attributes of our data. To scale our numeric data, we employed [Sci_Kit Learn’s StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). StandardScaler utilises standardization, which involves subtracting the mean from values and then dividing by the standard deviation. This results in values that are not constrained to a specific range (such as in normalization, where values will end up between 0 and 1). Standardization was chosen because it is less sensitive to outliers than normalization. This was useful as certain features of our data, such as *‘live’* and *‘spch’*, have instances that could be considered outlying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok53D5frDsi_"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "std_scaler = preprocessing.StandardScaler()\n",
        "train_numerical[train_num_attribs] = std_scaler.fit_transform(train_numerical[train_num_attribs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "036ucPl5CDiz"
      },
      "outputs": [],
      "source": [
        "train_numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K19ojzXP87KR"
      },
      "outputs": [],
      "source": [
        "###additionally scaling the test data\n",
        "test_numerical[test_num_attribs] = std_scaler.fit_transform(test_numerical[test_num_attribs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_aSduJJ9GS2"
      },
      "outputs": [],
      "source": [
        "test_numerical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHWbgkc_MBM1"
      },
      "source": [
        "After conducting a significant amount of preprocessing, we needed to rejoin our numerical and catergorical back together to create our final training and test sets that would be applied to our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTYqUudXE2Mp"
      },
      "outputs": [],
      "source": [
        "train_prepped = train_numerical.join(train_genre_collapsed)\n",
        "train_prepped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUY8xx559KE9"
      },
      "outputs": [],
      "source": [
        "test_prepped = test_numerical.join(test_genre_collapsed)\n",
        "test_prepped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vezCgLAgFGSL"
      },
      "outputs": [],
      "source": [
        "train_prepped = train_prepped.join(train_decade_enc)\n",
        "train_prepped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZgYYW-V9S9U"
      },
      "outputs": [],
      "source": [
        "test_prepped = test_prepped.join(test_decade_enc)\n",
        "test_prepped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVHQMNulFKQf"
      },
      "outputs": [],
      "source": [
        "train_prepped_FINAL = train_prepped\n",
        "train_prepped_FINAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yh4r-qB9ZkM"
      },
      "outputs": [],
      "source": [
        "test_prepped_FINAL = test_prepped\n",
        "test_prepped_FINAL = test_prepped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSVy5kkSGYZU"
      },
      "source": [
        "#Building Models\n",
        "\n",
        "After preparing our data, we then had to choose the various ML model(s) to use in our regression problem. We also had to paramatize these models, and potentially include them in ensemble methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "567yMZAgEDHh"
      },
      "source": [
        "***Support Vector Machine (SVM)***\n",
        "\n",
        "The first model we built and evaluated was a support vector machine (SVM). An SVM regressor (SVR) was chosen because of two reasons. First, SVMs are useful when dealing with small-to-medium sized datasets and we thought that this could also apply to our regression problem given that our training data contained less than 500 rows. Second, SVMs are capable of dealing with both linear and nonlinear data. This versatility meant that we could also apply polynomial features to our data if necessary.\n",
        "\n",
        "SVR operates on the opposite objective to SVM classification. Rather than attempting to limit margin violations within the margin and using the street to divide the dataset, SVR attempts to fit as many datapoints within the street whilst limiting margin violations outwith the margin.\n",
        "\n",
        "A SVR model was built and fit to the training data. The model and evaluation metric (RMSE) are coded below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "svm_reg = LinearSVR(epsilon = 1.5)\n",
        "svm_reg.fit(train_prepped_FINAL, train_target)"
      ],
      "metadata": {
        "id": "_8Jhp8yUsM6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred_svm = svm_reg.predict(train_prepped_FINAL)\n",
        "mse_svm = mean_squared_error(train_target, y_pred_svm)\n",
        "rmse_svm = np.sqrt(mse_svm)\n",
        "rmse_svm"
      ],
      "metadata": {
        "id": "Ap1wG_s7vE7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE score implies that the model, on average, is predicting a songs popularity at approximately 10 points away from the correct popularity. Although not a bad first attempt, it is evident that parameter tuning or another model would be required to achieve a lower RMSE."
      ],
      "metadata": {
        "id": "vrF3AOZBvWov"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUSk1fHEDTGY"
      },
      "source": [
        "***Random Forest***\n",
        "\n",
        "Random forests are an ensemble of decision trees trained via bagging method. We chose to explore the use of a Random Forest for many reasons. Firstly, it allowed us to test the effect of a decision tree regressor and bagging regressor on our data in a more efficent way. Further, random forests also provide a generally better overall model due to searching for the best feature amongst a random subset of features. Finally, despite their simplicity, Random Forests are one of the most powerful predicitive algorithms available, which makes it an ideal model to explore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DvAObOljGAQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "Rf_reg = RandomForestRegressor()\n",
        "Rf_reg.fit(train_prepped_FINAL, train_target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rf_reg_ypred = Rf_reg.predict(train_prepped_FINAL)\n",
        "Rf_reg_mse = mean_squared_error(train_target, Rf_reg_ypred)\n",
        "Rf_reg_rmse = np.sqrt(Rf_reg_mse)\n",
        "Rf_reg_rmse"
      ],
      "metadata": {
        "id": "-hfsRWKOT6Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest Regressor has given us our best score yet. This may be because Random Forests employ bagging, which allows for training instances to be used several times. This could have been beneficial due to the (relatively) small size of our training data and may have allowed for a reduction in both bias and variance when compared to a single model used on its own. With a low score using the default parameters, our next course of action is to find the best parameters for the data to see if it improves our RMSE score."
      ],
      "metadata": {
        "id": "PAU4ygVRj9Ax"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G-5ert1YrBR"
      },
      "source": [
        "***Polynomial Regression***\n",
        "\n",
        "As shown above (Figure 1), our data was incredibly noisy and not as straightforward as predicting results on a simple straight line. Thus, it was of interest to investigate the effect of creating polynomial features by adding powers of each feature as new features. This allows the model to find relationships between features that a simple Linear Regression is not cabable of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIsUAUgC-0nt"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly_features.fit_transform(train_prepped_FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyEYlJbRAJuz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "poly_lin_reg = LinearRegression()\n",
        "poly_lin_reg.fit(X_poly, train_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPF7tEPCAJ3l"
      },
      "outputs": [],
      "source": [
        "y_pred_poly = poly_lin_reg.predict(X_poly)\n",
        "poly_mse = mean_squared_error(train_target, y_pred_poly)\n",
        "poly_rmse = np.sqrt(poly_mse)\n",
        "poly_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmfKeXSAAO5O"
      },
      "source": [
        "The polynomial regression model has a lower rmse than the SVM, indicating that that polynomial features have performed well with the non-linear data, and reduced the RMSE. However, it is still nearly double the score of that produced by the random forest. Despite, the polynomial features it has still not produced a lower score than the random forest, however keeping in mind that poly features does reduce the RMSE will be useful when investigating ensemble methods.  \n",
        "\n",
        "The results of our individual models have provided a good starting point for further investigation. With the random forest performing best, it is of interest to see how it performs with different parameters and within ensemble methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPcc2IkOazIw"
      },
      "source": [
        "#Finding the Best Parameters\n",
        "\n",
        "Despite finding a fairly low RMSE score for the Random Forest Regressor, this was using the default parameters. To find the parameters which fit our data best we utilised the GridSearchCV() function to ensure that our model performed to the best extent. The parameters to search were obtained from [Sci-Kit Learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE0HVCJBbSPd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {\n",
        "    'n_estimators': [1, 100],\n",
        "    'max_depth': [1, 100],\n",
        "    'min_samples_leaf': [1, 100],\n",
        "    'max_leaf_nodes': [2, 100],\n",
        "    'n_jobs': [1, 100]\n",
        "}\n",
        "rf_reg2 = RandomForestRegressor()\n",
        "reg = GridSearchCV(rf_reg2, parameters, error_score='raise')\n",
        "reg.fit(train_prepped_FINAL, train_target)\n",
        "print(\"Best parameters found:\", reg.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-V_ImfYbtQ9"
      },
      "outputs": [],
      "source": [
        "### re-run models to see if it improves\n",
        "rf_reg2 = RandomForestRegressor(max_depth =100, max_leaf_nodes= 100, min_samples_leaf= 1, n_estimators= 100, n_jobs= 100)\n",
        "rf_reg2.fit(train_prepped_FINAL, train_target)\n",
        "rf_reg2_ypred = rf_reg2.predict(train_prepped_FINAL)\n",
        "rf_reg2_mse = mean_squared_error(train_target, rf_reg2_ypred)\n",
        "rf_reg2_rmse = np.sqrt(rf_reg2_mse)\n",
        "rf_reg2_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vmx2_4obzRo"
      },
      "source": [
        "The model run on the training set does not improve with the parameters found by the grid search, therefore indicating that the default parameters perform better. This could be a result of overfitting, which means the model performs well on the training data but generalises poorly to new instances. However, when uploading to kaggle our RMSE decreased by 0.01. Therefore, when assigning these default parameters, the model is better at generalising, which is ideal for when unseen data is applied to the model. As our strongest model so far, we decided to apply ensemble methods to see if it reduced the RMSE further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyd7xq3y2oUz"
      },
      "source": [
        "##Ensemble Methods\n",
        "\n",
        "Ensemble methods aim to aggregate the predicions of models to get better predictions than an individual predictor. Ensembles are found to work best when the models used are as independent from each other as possible, as different models are likely to make different types of errors and improve the ensembles overall accuracy. To explore the effects of ensembles in an attempt to lower our RMSE score, we created a boosted model and a stacked model to see if we could produce a better regressor."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Boosting***\n",
        "\n",
        "Boosting aims to combine a few weak learners into a singular strong learner by training each model sequentially where each model learns from the mistakes of its predecessor. This should create a more accurate predictor with a lower RMSE. As our original models performed fairly poorly, combining them alongside a strong random forest regressor could create a strong model.\n",
        "\n",
        "A Gradient Boosting Regressor (GBR) utilises boosting as described above, adding models successively in order to create a stronger overall model. However, rather than increase the importance of underfit training instances which is used by boosting models such as AdaBoost, GBR focuses on the residuals of the component models."
      ],
      "metadata": {
        "id": "uzbt49-VEYFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gbr = GradientBoostingRegressor()\n",
        "gbr.fit(train_prepped_FINAL, train_target)\n",
        "gbr_ypred = gbr.predict(train_prepped_FINAL)\n",
        "gbr_mse = mean_squared_error(train_target, gbr_ypred)\n",
        "gbr_rmse = np.sqrt(gbr_mse)\n",
        "gbr_rmse"
      ],
      "metadata": {
        "id": "zaKmAeI08KUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gradient Boosting Regressor performed significantly better than the linear SVR and linear regression models on their own, however was still not as strong as the Random Forest Regressor on its own.\n",
        "\n",
        "Gradient Boosting Regressor shares some parameters with the Random Forest regressor. We ran a second GBR with the parameters set in our second Random Forest Regressor, to see if that would improve performance."
      ],
      "metadata": {
        "id": "DnavdnLSLRuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbr = GradientBoostingRegressor(max_depth = 100, n_estimators = 100)\n",
        "gbr.fit(train_prepped_FINAL, train_target)\n",
        "gbr_ypred = gbr.predict(train_prepped_FINAL)\n",
        "gbr_mse = mean_squared_error(train_target, gbr_ypred)\n",
        "gbr_rmse = np.sqrt(gbr_mse)\n",
        "gbr_rmse"
      ],
      "metadata": {
        "id": "kdhAJKI1ZhGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An RMSE this low potentially indicates that the second GBR model is dramatically overfitting the data. Even though a Random Forest Regressor with similar parameters was performing relatively well, this was not the case with boosting. This may be because the bagging method employed by a RF Regressor allows it to generalize to data better."
      ],
      "metadata": {
        "id": "G2qBxfDSbLSw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWFQ1lXMI9XS"
      },
      "source": [
        "***Stacking***\n",
        "\n",
        "With success on our individual models only found in the random forest model, we attempted to stack our models to aggagate the predictions. Stacking takes several model's predictions and uses them to make a final prediction utilising a *meta learner*. The training data is split into subsets, with one being used to train the component predictors. The component predictors then predict on the second subset of the training data, and these predictions are fed into a new set as features. The meta learner is then trained on this resulting dataset.\n",
        "\n",
        "Our base models were those originally examined indivdually, again for the reasons discussed above. These are very different models, which would allow them to make different errors from which the meta regressor could learn from and to make accurate predictions. For our 'meta' regressor, we selected a the random forest regressor to predict the songs popularity. As our best performing model, it made sense to have this as the meta learner."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "base_models = [\n",
        "    ('svm', LinearSVR()),\n",
        "    ('gradient_boosting', GradientBoostingRegressor()),\n",
        "    ('lin_regressor', LinearRegression())]\n",
        "meta_regressor = RandomForestRegressor(max_depth = 100 , max_leaf_nodes= 100, min_samples_leaf= 1, n_estimators= 100, n_jobs= 100)\n",
        "stacked_model = StackingRegressor(estimators=base_models, final_estimator=meta_regressor)\n",
        "stacked_model.fit(train_prepped_FINAL, train_target)"
      ],
      "metadata": {
        "id": "qsCHUUz-P6tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_ypred = stacked_model.predict(train_prepped_FINAL)\n",
        "stacked_mse = mean_squared_error(train_target, stacked_ypred)\n",
        "stacked_rmse = np.sqrt(stacked_mse)\n",
        "stacked_rmse"
      ],
      "metadata": {
        "id": "IPaWAXH3QL58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite, stacking different models, it has not improved our RMSE score and has in fact increased it. This may imply that the model is not learning from its predessors and is struggling to make more accurate predictions. As shown earlier, using polynomial features decreased the RMSE score, so it may be useful try this in the stacked regressor to see if this reduces the RMSE."
      ],
      "metadata": {
        "id": "t3NpgbSEQj1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5VbtPKSBpq3"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "base_models2 = [\n",
        "    ('svm', LinearSVR()),\n",
        "    ('gradient_boosting', GradientBoostingRegressor()),\n",
        "    ('lin_regressor', LinearRegression())]\n",
        "meta_regressor2 = RandomForestRegressor(max_depth = 100 , max_leaf_nodes= 100, min_samples_leaf= 1, n_estimators= 100, n_jobs= 100)\n",
        "stacked_model2 = StackingRegressor(estimators=base_models, final_estimator=meta_regressor)\n",
        "stacked_model2.fit(X_poly, train_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7TQexVzJQeC"
      },
      "outputs": [],
      "source": [
        "stacked_ypred2 = stacked_model2.predict(X_poly)\n",
        "stacked_mse2 = mean_squared_error(train_target, stacked_ypred2)\n",
        "stacked_rmse2 = np.sqrt(stacked_mse2)\n",
        "stacked_rmse2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQwQRyT35681"
      },
      "source": [
        "Using a stacked model with polynomial features did improve the RMSE score, decreasing by approximately 3 from the non-polynomial stacked model. However, the score is still not as efficient as our simple random forest regressor. This could be because in our original stacked model, the component predictors, such as Linear Regression and SVR, were perhaps too simple for the data they were being fit to. Adding polynomial features improved their performance, but not as well as the RFR. Another reason for the disparity in performance may be because the RFR can already model nonlinear data, without the need for feature transformation, meaning it can operate on data with lower dimensionality.\n",
        "\n",
        "Even with polynomial features added, a stacked model still underpeformed in comparison to our Random Forest. One reason may be that the stacking algorithm involves splitting the dataset into subsets. This may have been counterproductive in our case given that our training data already had a small number of instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ys-zYQe6wVO"
      },
      "source": [
        "#Final Solution\n",
        "\n",
        "After trying, testing and tuning a variety of models, it is evident from the RMSE scores that the Random Forest Regressor, with the parameters found via grid search, was the most accurate in producing the predicted popularity of the songs. Despite polynomial features performing well in previous models, Random Forests are already suited to handling non linear data without the need to add extra features. There, we decided to not create our final model with polynomial features. Although simple, the Random Forest Regressor has produced the most effective score to predict the popularity of songs. This implies that although ensemble methods can improve a models performance, it is not necessarily always true and depending on the type and structure of the data, some ensemble learning methods will perform better than others.The code from our final model is shown below, followed by the predictions that were used to submit to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_W7QKQ37Nyy"
      },
      "outputs": [],
      "source": [
        "final_model = RandomForestRegressor(max_depth =100, max_leaf_nodes= 100, min_samples_leaf= 1, n_estimators= 100, n_jobs= 100)\n",
        "final_model.fit(X_poly, train_target)\n",
        "\n",
        "final_model_ypred = final_model.predict(X_poly)\n",
        "final_model_mse = mean_squared_error(train_target, final_model_ypred)\n",
        "final_model_rmse = np.sqrt(final_model_mse)\n",
        "final_model_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To assess our model's generalisability, we created a learning curve to assess our model's performance on training data versus validation data. To do this we had to split our existing training data into a test and train set, because we lack the test data's targets."
      ],
      "metadata": {
        "id": "uD1DnnyQVqP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the training data into training and testing sets because we don't have the test target\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_prepped_FINAL, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BvaYeTLYYbYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(max_depth=100, max_leaf_nodes=100, min_samples_leaf=1, n_estimators=100, n_jobs=100)"
      ],
      "metadata": {
        "id": "uAWX6LNkIzl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the learning curve\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    rf_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10))"
      ],
      "metadata": {
        "id": "JTUZYFMzI6Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating mean and standard deviation of training and validation scores\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = -np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)"
      ],
      "metadata": {
        "id": "RQU75AOOJEUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting learning curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_mean, label='Training Error', marker='o')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
        "\n",
        "plt.plot(train_sizes, test_mean, label='Validation Error', marker='o')\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.15, color='green')\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('Negative Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KtA9V7e7JHui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mY6msohZG-D"
      },
      "source": [
        "The learning curve shows that the model is significantly overfitting to the split training data. This meant that our model is detecting patterns within the dataset and thus will not generalise well to new instances. It should be noted that this graph, whilst informative, is not plotted against the *actual test data*, because the test targets are not available. Whilst this does reduce the overall relevance of the learning curve in the context of our test data, it is still a potentially informative indicator of the performance of our regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CTxmsED6268"
      },
      "source": [
        "# Kaggle Performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_kaggle = final_model.predict(X_poly)\n",
        "test_data_set = pd.read_csv(\"CS98XRegressionTest.csv\")\n",
        "final_submission = pd.DataFrame(columns=['Id', 'pop'])\n",
        "final_submission['pop'] = kaggle\n",
        "final_submission['Id'] = test_data_set['Id']\n",
        "excel_filename = 'Final_submission.xlsx'\n",
        "final_submission.to_excel(excel_filename, index=False)\n",
        "print(f'Data exported to {excel_filename}')"
      ],
      "metadata": {
        "id": "w5UQAB9_T8vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "When uploading our final model to Kaggle, our RMSE score was: 7.36."
      ],
      "metadata": {
        "id": "SqKxtTclo1Ir"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}